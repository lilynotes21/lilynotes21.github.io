---
title: 'Project 1: Exploratory Data Analysis'
author: "SDS348"
date: '2021-05-08'
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F,
tidy=TRUE, tidy.opts=list(width.cutoff=60), R.options=list(max.print=100))
```

## Data Wrangling and Data Exploration

## Lily Tapia (lmt2622)

### Instructions
A knitted R Markdown document (ideally HTML) and the raw R Markdown file (as .Rmd) should both be submitted to Canvas by 11:59pm on the due date. These two documents will be graded jointly, so they must be consistent (i.e., donâ€™t change the R Markdown file without also updating the knitted document).

The text of the document should provide a narrative structure around your code/output. All results presented must have corresponding code. Any answers/results/plots etc. given without the corresponding R code that generated the result will not be considered. Furthermore, all code contained in your final project document must work correctly (knit early, knit often)! Please do not include any extraneous code or code which produces error messages. (Code that produces warnings is acceptable, as long as you understand what the warnings mean!)

    
### Rubric

Prerequisite: Finding appropriate data from at least two sources per the instructions above: Failure to do this will result in a 0! You will submit a .Rmd file and a knitted document (html/pdf).

#### 0. Introduction (5  pts)

  In this project, I will be looking at relationships between the IMDb ratings, number of votes and    metascores of movies and shows that Disney+ and Netflix have in common. The two datasets that I am using, disney_plus_shows and netflix_titles, contain characteristics of shows and movies from the streaming services of Disney+ and Netflix. The disney_plus_shows dataset has been renamed to disney_plus for convenience and it contains 992 observations and 19 variables, three of which are numeric. The disney_plus dataset contains the following variables for each movie or show title: imdb ID, type (movie or show), plot, rate, year, date of release and date added to Disney+, runtime, genre, director, writer, actors, language, country, awards, metascore, and imdb rating and votes. The netflix_titles has been renamed to netflix_ for convenience and contains 7739 observations and 12 variables. The netflix_ dataset contains the following variables for each movie or show title: ID, title, type (movie or show), director, cast, date added to Netlix, country, year released, rating, duration, category the movie or show is listed in and description. These datasets were acquired through Kaggle and downloaded as csv files.
  
  I chose these datasets because my family is full of movie and tv show series fanatics, and we actively use both of these streaming services. Also, I was interested in finding out what shows and movies Disney+ and Netflix have in common as well as the data for these shows and movies. Furthermore, I expect the two datasets to only share a select number of movies and shows. 

```{R}
#The two datasets and codes used rename the datasets are shown below:
library(tidyverse)
library(dplyr)
library(readr)
disney_plus_shows <- read_csv("disney_plus_shows.csv", 
    col_types = cols(metascore = col_number(), 
        imdb_rating = col_number(), imdb_votes = col_number()))
library(readr)
netflix_titles <- read_csv("netflix_titles.csv")
disney_plus <- disney_plus_shows
netflix_ <- netflix_titles
```


#### 1. Tidying: Rearranging Wide/Long (10 pts)

  My datasets were already tidy, so I used the pivot_longer and pivot_wider functions to untidy and tidy my summary statistics. Pivot_longer was used to untidy the data by placing all of the statistical functions in one column and all of the results from each statistical function in one column: this actually helped me better see all of the summary statistics for each numeric variable. Pivot_wider was then used to tidy the data so that each row or result is relevant to each statistical function for each numeric variable. 

```{R}
#codes from joining: 
disnet <- inner_join(disney_plus,netflix_, by="title")
disnet1 <- subset(disnet, select = -c(20,21,22,23,24,25,26,27,28,29,30))
head(disnet1)
#codes for finding summary statistics overall: 
disnet1_summarize_stats<- disnet1%>% summarize_if(is.numeric, list(mean=mean,sd=sd, min=min, max=max, n_distinct=n_distinct), na.rm=T)
disnet1_summarize_stats
#untidying and tidying summary statistics:
untidydisnetsum <- disnet1_summarize_stats %>% pivot_longer(1:15, names_to="functions", values_to="results")
untidydisnetsum
tidydisnetsum <- untidydisnetsum%>% group_by(functions) %>% mutate(row = row_number()) %>%tidyr::pivot_wider(names_from = functions, values_from = results) %>%select(-row)
head(tidydisnetsum)
```

    
#### 2. Joining/Merging (10 pts)
    
  I joined the two datasets using inner_join and named this joined dataset 'disnet'. I chose to use inner_join because I wanted to focus on only the movies and tv shows (or titles) Disney+ and Netflix shared and drop all of the titles the two datasets did not share. When joined using inner_join, 8,579 titles were dropped that did not match between both datasets from the 8612 total titles. This left the new dataset with only 33 observations total and 32 unique titles total. After joining the datasets, there were duplicate variables from the Neflix dataset that I dropped using subset() and select() which indexed and selected the duplicated variables I wanted to drop. This left the final joined dataset, named 'disnet1', with 33 observations and 19 columns.
  
```{R}
disnet <- inner_join(disney_plus,netflix_, by="title")
disnet1 <- subset(disnet, select = -c(20,21,22,23,24,25,26,27,28,29,30))
head(disnet1)
```


#### 3. Wrangling (40 pts)
    
  First, I used the filter(), select() and arrange() functions to explore my data. I used these functions in combination to find which title has the highest number of IMDb votes in the USA; this result was the movie title "Black Panther". I then used mutate to create a new variable that was a function of imdb votes and ratings which produced the proportion of IMDb ratings to IMDb votes. I also used group_by() to explore the number of titles in each language and country and I found that the most titles (16 titles) are in English and in the USA. 
 
  To calculate the overall summary statistics of the numeric variables in my dataset, I used summarize(). I found that the mean IMDb rating was about 6.697, the mean number of IMDb votes was 95,835.03 and the mean metascore was about 60.526. I then calculated the summary statistics grouped by language. I found that the language category with the highest mean imdb votes was 'English, Swahili, Nama, Xhosa, Korean' while the language with the highest mean IMDb rating was 'English, Spanish, Indonesian, Chinese, Arabic, Russian, Hindi, Tibetan, Portuguese, French, Thai, Norwegian, Italian, Japanese, Mongolian, Kazakh' which is interesting, but makes sense since this language category offers the largest range of languages for movies or shows. Lastly, I used the cor() function to evaluate which pairs of my numeric variables have any correlation with one another; metascore and IMDb rating were the only pair that have the highest correlation, but this correlation is not very strong. 
 
```{R}
#Filter, arrange and select functions:
head(disnet1 %>% 
  filter(country.x=="USA") %>% 
  select(title, imdb_votes) %>% 
  arrange(desc(imdb_votes)))
#Group_by using 2 variables:   
disnetlangcount<- disnet1 %>% group_by(language,country.x) %>% summarize(count=n())
head(disnetlangcount)
#Using mutate():
disnet_function <- disnet1 %>% 
  mutate(imdb_rating_per_votes = imdb_rating/imdb_votes)
head(disnet_function)
#Summary statistics overall:
disnet1_summarize_stats<- disnet1 %>% summarize_if(is.numeric, list(mean=mean,sd=sd,min=min,max=max,n_distinct=n_distinct), na.rm=T)
head(disnet1_summarize_stats)
#Summarize using group_by:
groupbylanguagestats <- disnet1 %>% group_by(language) %>% summarize_if(is.numeric, list(mean=mean,sd=sd), na.rm=T)
  head(groupbylanguagestats)
#Correlation:
cordisnet <- disnet1 %>% select_if(is.numeric)%>% cor(use="pair")
cordisnet
```
  
#### 4. Visualizing (30 pts)
    
  The correlation heatmap represents the correlation between the numeric variables in the disnet1 dataset. This graph showed that the pair of numeric variables that had the highest correlation (0.68) in my dataset were metascore and IMDb rating. However, this graph also shows that most of the other variables do not have strong correlations between each other and are instead more independent since their correlation coefficients are closer to zero than -1 or 1. 
 
  The scatterplot shows the relationship between IMDb votes and ratings in the disnet1 between the different types of titles (movies or series). From the graph, it can be concluded that the majority of movies and series have an IMDb rating between the range of about 6-8. Also, movies have a higher number of IMDb votes than series overall. However, it does not seem that there is a strong relationship between the number of IMDb votes and IMDb rating; even when rated higher, some movies and series still had a lower number of IMDb votes. 
  
  Finally, I used a barplot to compare the number of IMDb votes to the rating of a movie or series. For this barplot, I decided to use filter() and make another dataset version of 'disnet1' called 'disnet2' which would contain only movies and series rated "G", "PG", or "PG-13" because there are a couple duplicates of these ratings that are called different names like "TV-G", and because I just wanted to focus on the most familiar ratings. After wrangling my dataset, I found that movies rated PG-13 had the highest number of IMDb votes compared to other ratings. Another interesting result is that it appears that in the 'disnet2' dataset, only movies were categorized as rated G, PG or PG-13 since the color purple which indicates series did not appear under these categories of 'rated'. 
   
```{R}
#Correlation Heatmap
tidycordisnet <- cordisnet%>% as.data.frame %>% rownames_to_column("var1")%>% pivot_longer(-1, names_to="var2", values_to="correlation")
tidycordisnet %>% ggplot(aes(var1, var2, fill=correlation))+geom_tile()+scale_fill_gradient2(low="yellow", mid="white", high="red")+
  geom_text(aes(label=round(correlation,2)), color="black", size=4)+
  coord_fixed()+theme(axis.text.x = element_text(angle=90, hjust=1))+ ggtitle("Correlation in IMDb Votes, IMDb Rating & Metascore")+ theme(plot.title = element_text(hjust = 0.5))
 
#Scatterplot
  ggplot(disnet1, aes(imdb_rating, imdb_votes, color=type.x))+geom_point() +
    theme(legend.position=c(.9,.5))+ scale_color_manual(breaks = c("movie", "series"),values=c("orange", "red"))+ scale_y_continuous(limits = c(0, 600000), breaks = seq(0, 600000, by = 100000))+ ggtitle("IMBd Votes vs IMBd Rating")+ ylab("IMDb Votes") + xlab("IMDb Rating")+theme(plot.title = element_text(hjust = 0.5)) 

#Barplot
disnet2 <- disnet1%>%filter(rated=="G" & rated=="PG" & rated=="PG-13")
target <- c("G", "PG", "PG-13")
disnet2<- filter(disnet1, rated %in% target)
ggplot(disnet2, aes(x = rated, y = imdb_votes, fill=type.x))+
  geom_bar(stat="summary", fun=mean, position="dodge", na.rm = T)+
 geom_errorbar(stat="summary", fun.data=mean_se, position="dodge", na.rm = T)+ggtitle("IMDb Votes Related to Rate")+ xlab("Rated")+ylab("IMDb Votes")+theme(plot.title = element_text(hjust = 0.5))
```

#### 5. Dimensionality Reduction (30 pts) 
  
  I first created another dataset from my original dataset with dropped NA values in order to cluster my data. After doing this, my new data set contained 19 total observations instead of the 33 original observations. I also only selected my numeric variables in this new dataset. 
 
  Then, I decided to cluster my data by 3 clusters; 2 clusters would have been optimal, but it seemed easier to visualize my data using 3 clusters. After I clustered my numeric data (metascore, IMDb votes and ratings) using 3 clusters, I found that the average silhouette width was about 0.66 which means that a reasonable structure has been found, but it could be stronger. Furthermore, I found that overall, titles with metascores higher than about 60 seemed to have higher IMDb ratings. Also, titles in cluster 1 had higher metascores, IMDb ratings and IMDb votes overall. However, it was harder to see any relationship between these variables for titles in clusters 2 and 3; as metascore or IMDb rating increased, the number of IMDb votes for these clusters did not fluctuate significantly. 
  
```{R}
disnetmeans <- disnet1 %>% na.omit() %>% select("metascore", "imdb_rating", "imdb_votes")
library(cluster)
sil_width <- vector()#empty vector to hold mean sil width
for(i in 2:10){  
  kms <- kmeans(disnetmeans,centers=i) #compute k-means solution
  sil <- silhouette(kms$cluster,dist(disnetmeans)) #get sil widths
  sil_width[i]<-mean(sil[,3]) #take averages (higher is better)
}
ggplot()+geom_line(aes(x=1:10, y=sil_width))+ scale_x_continuous(name="k", breaks = 1:10)+labs(x= "k (fixed number of clusters)", y= "Silhouette Width", title= "Kmeans Clustering")+
  theme(plot.title = element_text(hjust = 0.5))
kmeans2 <- disnetmeans %>% kmeans(3) #3 centers, or number of clusters
kmeans2
kmeans2$size #how many in each cluster
kmeans2clust <- disnetmeans %>% as.data.frame %>% mutate(cluster=as.factor(kmeans2$cluster))
kmeans2clust
#visualizing clustered data
library(GGally)
ggpairs(kmeans2clust, columns=1:3, aes(color=cluster), upper = NULL)

library(cluster)
pam1<-kmeans2clust%>%pam(k=3)
pam1
disnet1[pam1$id.med,]
pam1$silinfo$avg.width #average silhouette width
plot(pam1, which=2) #gives avg silhouette width and silhouette widths of each cluster.
```

### Dataset Sources

- Disney+ https://www.kaggle.com/unanimad/disney-plus-shows
- Netflix https://www.kaggle.com/shivamb/netflix-shows
...






